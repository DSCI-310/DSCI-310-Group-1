{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8258eaf2",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a601360d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option(\"display.max_rows\", 15, \"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4eaec63-4e76-4491-b65d-7d88671f794a",
   "metadata": {},
   "source": [
    "At the very first of the exploratory analysis process, it is always helpful to take a glance at the structures and details of the raw dataset we archived from the [UCI ML Repo](https://archive-beta.ics.uci.edu/ml/datasets/student+performance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3a2e4ddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>395 rows Ã— 0 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, ...]\n",
       "\n",
       "[395 rows x 0 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('../data/raw/student-mat.csv', sep = \";\").iloc[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f5df4a-da37-445c-bfd0-ff987c8f43eb",
   "metadata": {},
   "source": [
    "Then, we decided on a train test split of 80% training and 20% testing. This was because the number of samples in the dataset where moderately low (396) so we wanted more samples to train on. Using panda's describe all and styler to make a table, we can find many useful pieces of information for all of our features inside the training set. For numerical features, we can see interesting pieces of info such as the average mother education is higher than the average father education. Furthermore, for categorical variables, we can see interesting info such as the most frequent parent status in our training set is that they are still living together and most people are not in a romantic relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ea7f168a-a393-42e7-b250-48484252cd87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>studytime</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>goout</th>\n",
       "      <th>romantic</th>\n",
       "      <th>traveltime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>316.000000</td>\n",
       "      <td>316</td>\n",
       "      <td>316.000000</td>\n",
       "      <td>316.000000</td>\n",
       "      <td>316</td>\n",
       "      <td>316</td>\n",
       "      <td>316.000000</td>\n",
       "      <td>316</td>\n",
       "      <td>316.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>unique</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>top</td>\n",
       "      <td>NaN</td>\n",
       "      <td>T</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>freq</td>\n",
       "      <td>NaN</td>\n",
       "      <td>290</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>115</td>\n",
       "      <td>174</td>\n",
       "      <td>NaN</td>\n",
       "      <td>209</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mean</td>\n",
       "      <td>2.047468</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.797468</td>\n",
       "      <td>2.547468</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.120253</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.436709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>std</td>\n",
       "      <td>0.843816</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.067616</td>\n",
       "      <td>1.090053</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.091715</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.680182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>min</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>25%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>50%</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>75%</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>max</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   studytime Pstatus        Medu        Fedu   Mjob   Fjob  \\\n",
       "0       count  316.000000     316  316.000000  316.000000    316    316   \n",
       "1      unique         NaN       2         NaN         NaN      5      5   \n",
       "2         top         NaN       T         NaN         NaN  other  other   \n",
       "3        freq         NaN     290         NaN         NaN    115    174   \n",
       "4        mean    2.047468     NaN    2.797468    2.547468    NaN    NaN   \n",
       "5         std    0.843816     NaN    1.067616    1.090053    NaN    NaN   \n",
       "6         min    1.000000     NaN    1.000000    0.000000    NaN    NaN   \n",
       "7         25%    1.000000     NaN    2.000000    2.000000    NaN    NaN   \n",
       "8         50%    2.000000     NaN    3.000000    2.500000    NaN    NaN   \n",
       "9         75%    2.000000     NaN    4.000000    4.000000    NaN    NaN   \n",
       "10        max    4.000000     NaN    4.000000    4.000000    NaN    NaN   \n",
       "\n",
       "         goout romantic  traveltime  \n",
       "0   316.000000      316  316.000000  \n",
       "1          NaN        2         NaN  \n",
       "2          NaN       no         NaN  \n",
       "3          NaN      209         NaN  \n",
       "4     3.120253      NaN    1.436709  \n",
       "5     1.091715      NaN    0.680182  \n",
       "6     1.000000      NaN    1.000000  \n",
       "7     2.000000      NaN    1.000000  \n",
       "8     3.000000      NaN    1.000000  \n",
       "9     4.000000      NaN    2.000000  \n",
       "10    5.000000      NaN    4.000000  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('../results/exploratory-stu-mat.csv', sep = \",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c739df5-e7bf-4fca-adeb-56f5ac0014de",
   "metadata": {},
   "source": [
    "From these numeric features, we can see that for the most part, there is no relation between these features and predicted grade. The only truly interesting thing to note is that with higher travel time, it seems that the range of grades gets narrower and narrower such that the low end of the range is higher than lower values of travel time, but the high end of the range is also much lower compared to lower values of travel time. Of course, it is difficult to say whether this is true or not given the low number of samples for higher travel time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b83fb74-418c-45aa-bfac-b807e052148a",
   "metadata": {},
   "source": [
    ":::{figure-md} num-fig\n",
    "<img src=\"../results/figures/explore_numeric.png\" alt=\"num\" class=\"bg-primary mb-1\" width=\"550px\">\n",
    "\n",
    "This is a caption in **Markdown**!\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26559af5-e76b-477c-a61e-9cb85f82a6e3",
   "metadata": {},
   "source": [
    ":::{figure-md} cat-fig\n",
    "<img src=\"../results/figures/explore_cat.png\" alt=\"cat\" class=\"bg-primary mb-1\" width=\"550px\">\n",
    "\n",
    "This is a caption in **Markdown**!\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47a0e81-ceab-4cbf-bd65-313e80eba071",
   "metadata": {},
   "source": [
    "From this exploratory categorical variable analysis, we can see that for some of these variables, we have a big imbalance between classes. This is especially prominent in P status and Father job. The consequence of this is that the coefficient end up not being very useful in terms of predicting grades as, for example, P status = t may have lots of representation in high and low categories. Furthermore, given the low amount of P status = A, the model we use might misrepresent the data if all of the \"A\" values end up being either high or low grades, and not a mix of both when we apply our model to the test set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
