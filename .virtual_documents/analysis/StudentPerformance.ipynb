import sys
sys.path.append('..'),
from src import splitxy
from src import listfun
from src import plotSquareData

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from sklearn import datasets
from sklearn.compose import make_column_transformer
from sklearn.linear_model import LinearRegression, Ridge
from sklearn.model_selection import (
    cross_validate,
    train_test_split,
    RandomizedSearchCV
)
from sklearn.metrics import mean_squared_error
from sklearn.pipeline import Pipeline, make_pipeline
from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler
from sklearn.impute import SimpleImputer
import urllib.request
import zipfile


#inspiration for learning how to download from web taken from https://stackoverflow.com/questions/41218216/using-pandas-to-download-load-zipped-csv-file-from-url
URL = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00320/student.zip'
location, _ = urllib.request.urlretrieve(URL)
compressed_file = zipfile.ZipFile(location)
csv_file = compressed_file.open('student-mat.csv')
df = pd.read_csv(csv_file,sep = ";")
pd.set_option("display.max_rows", 10, "display.max_columns", None)
df.head()


#save a copy of the dataframe 
df.to_csv('../data/raw/student-mat.csv', index=False)


train_df, test_df = train_test_split(df, test_size = 0.2, random_state=100)

#make training and testing split
desiredfeatures = ["studytime", "Pstatus", "Medu", "Fedu", "Mjob", "Fjob", "goout","romantic","traveltime"]
X_train, y_train = splitxy.splitxy(train_df, desiredfeatures, "G3")
X_test, y_test = splitxy.splitxy(test_df, desiredfeatures, "G3")


describer = X_train.describe(include="all")
describer.style.set_caption("Figure 1.0. A table desplaying the most common values of each categorical variable along side percentiles of numerical variables")


desiredFeatures = ["studytime", "Medu", "Fedu", "goout", "traveltime"]
titles = ["study time vs grade", "Mother education vs grade", "Father education vs grade", 
                                     "time spent with friends vs grade", "travel time vs grade"]
txt = "Figure 2 A series of plots examining the numeric features compared to predicted grade"
plotSquareData.plot_square_data(X_train, y_train, desiredFeatures, titles, txt) 


desiredFeatures = ["Pstatus", "Mjob", "Fjob", "romantic"]
titles = ["P status vs grade", "Mother job vs grade", "Father Job vs grade", "Relationship status vs grade"]
txt = "Figure 3 A series of histograms examining the distribution of categorical features"
plotSquareData.plot_square_data(X_train, y_train, desiredFeatures, titles, txt)


#preprocess the data to make sure the scaling is correct and the categorical variables are encoded properly
numeric_features = ["studytime", "Medu", "Fedu", "goout", "traveltime"]
categorical_features = ["Mjob", "Fjob"]
binary_features = ["Pstatus", "romantic"]

preprocessor = make_column_transformer(
    (make_pipeline(SimpleImputer(), StandardScaler()), numeric_features), 
    (make_pipeline(SimpleImputer(strategy="constant", fill_value="missing"), OneHotEncoder(handle_unknown="ignore", sparse=False)), categorical_features),
    (make_pipeline(SimpleImputer(strategy="most_frequent"), OneHotEncoder(drop="if_binary", dtype=int)), binary_features),
)



#create the pipeline to preprocess our data and apply linear regression
pipelr = make_pipeline(preprocessor, Ridge(random_state=123))

hyperparams = np.exp(np.random.uniform(-3, 3, 10))

param_dist = {"ridge__alpha": hyperparams}

rand_search = RandomizedSearchCV(pipelr, param_dist, n_jobs = -1, scoring = "neg_root_mean_squared_error")
rand_search.fit(X_train, y_train)

print(rand_search.best_params_)
print(rand_search.best_score_)


df_results = pd.DataFrame(rand_search.cv_results_)
df_results2 = df_results[df_results.rank_test_score < 5].drop(["mean_score_time",
                                                             "std_score_time",
                                                             "split0_test_score",
                                                             "split1_test_score",
                                                             "split2_test_score",
                                                             "split3_test_score",
                                                             "split4_test_score"], axis=1)
df_results2


pipelr2 = make_pipeline(preprocessor, Ridge(alpha = rand_search.best_params_['ridge__alpha']))
pipelr2.fit(X_train, y_train)

predicted = pipelr2.predict(X_test)
rms = mean_squared_error(y_test, predicted, squared=False)
df_final = df_results[df_results.rank_test_score == df_results.rank_test_score.min()].drop(["mean_score_time",
                                                                                             "std_score_time",
                                                                                             "split0_test_score",
                                                                                             "split1_test_score",
                                                                                             "split2_test_score",
                                                                                             "split3_test_score",
                                                                                             "split4_test_score"], axis=1)
df_final["final score"] = -rms
df_final


print("The final RMSE error is:", rms) 


plt.title("Predicted Grade vs True Grade")
plt.scatter(y_test, predicted, alpha=0.3)
grid = np.linspace(y_test.min(), y_test.max(), 1000)
plt.plot(grid, grid, "--k")
plt.xlabel("true grade")
plt.ylabel("predicted grade")
txt = "Figure 4. A plot displaying the relation between the predicted grade and the actual grade"
plt.figtext(0.5, -0.05, txt, wrap=True, horizontalalignment='center', fontsize=12)


#ohe_columns = listfun.list_abs(preprocessor, "pipeline-2", "onehotencoder", categorical_features)
ohe_columns = listfun.list_abs(preprocessor, "pipeline-2", "onehotencoder", categorical_features)
ohe_columns2 = listfun.list_abs(preprocessor, "pipeline-3", "onehotencoder", binary_features)

new_columns = numeric_features + ohe_columns + ohe_columns2

df_coeff = pd.DataFrame(
    data={
        "features": new_columns,
        "coefficients": pipelr2.named_steps["ridge"].coef_,
    }
)


ohe_columns2


df_coeff.sort_values("coefficients",ascending=False)
